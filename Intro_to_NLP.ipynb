{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMyP8CXWfhKcJrcNGz9E75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshandahal/MachineLearning/blob/main/Intro_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "szdrARpDents"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sent = \" Tokenization is the task of splitting text into meaning segments, caled tokens\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p4gSuONep4_",
        "outputId": "1d15108a-7227-4848-81f3-58bb425c5956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbb3gEu8e2gO",
        "outputId": "2c0f5046-ea56-4ba7-9586-43fac2de1e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tokenization',\n",
              " 'is',\n",
              " 'the',\n",
              " 'task',\n",
              " 'of',\n",
              " 'splitting',\n",
              " 'text',\n",
              " 'into',\n",
              " 'meaning',\n",
              " 'segments',\n",
              " 'caled',\n",
              " 'tokens']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'I like football. She like playing with heart'"
      ],
      "metadata": {
        "id": "djtl9qHRftBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.sent_tokenize(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsItuqxxgKLM",
        "outputId": "f26d107f-d093-4dcf-aee5-35249eaebcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I like football.', 'She like playing with heart']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQcmC88ugObC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Words\n",
        " you may want to filter out so called stopwords that are too common and dont add any meaning like \"the\", \"and\", and \"but\""
      ],
      "metadata": {
        "id": "Y3yAWvRnhEjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh29KxdYhHNq",
        "outputId": "6e0c6034-2a09-4eb7-a602-fa41a91b743f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.stopwords.words(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxH8eTgXhhnN",
        "outputId": "c293b2b9-f12d-488a-9715-43b63a6b74b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.stopwords.words(\"nepali\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36JQ4FWGhs5E",
        "outputId": "0d8a1564-f50c-42ba-f740-d1081eb4a5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['छ',\n",
              " 'र',\n",
              " 'पनि',\n",
              " 'छन्',\n",
              " 'लागि',\n",
              " 'भएको',\n",
              " 'गरेको',\n",
              " 'भने',\n",
              " 'गर्न',\n",
              " 'गर्ने',\n",
              " 'हो',\n",
              " 'तथा',\n",
              " 'यो',\n",
              " 'रहेको',\n",
              " 'उनले',\n",
              " 'थियो',\n",
              " 'हुने',\n",
              " 'गरेका',\n",
              " 'थिए',\n",
              " 'गर्दै',\n",
              " 'तर',\n",
              " 'नै',\n",
              " 'को',\n",
              " 'मा',\n",
              " 'हुन्',\n",
              " 'भन्ने',\n",
              " 'हुन',\n",
              " 'गरी',\n",
              " 'त',\n",
              " 'हुन्छ',\n",
              " 'अब',\n",
              " 'के',\n",
              " 'रहेका',\n",
              " 'गरेर',\n",
              " 'छैन',\n",
              " 'दिए',\n",
              " 'भए',\n",
              " 'यस',\n",
              " 'ले',\n",
              " 'गर्नु',\n",
              " 'औं',\n",
              " 'सो',\n",
              " 'त्यो',\n",
              " 'कि',\n",
              " 'जुन',\n",
              " 'यी',\n",
              " 'का',\n",
              " 'गरि',\n",
              " 'ती',\n",
              " 'न',\n",
              " 'छु',\n",
              " 'छौं',\n",
              " 'लाई',\n",
              " 'नि',\n",
              " 'उप',\n",
              " 'अक्सर',\n",
              " 'आदि',\n",
              " 'कसरी',\n",
              " 'क्रमशः',\n",
              " 'चाले',\n",
              " 'अगाडी',\n",
              " 'अझै',\n",
              " 'अनुसार',\n",
              " 'अन्तर्गत',\n",
              " 'अन्य',\n",
              " 'अन्यत्र',\n",
              " 'अन्यथा',\n",
              " 'अरु',\n",
              " 'अरुलाई',\n",
              " 'अर्को',\n",
              " 'अर्थात',\n",
              " 'अर्थात्',\n",
              " 'अलग',\n",
              " 'आए',\n",
              " 'आजको',\n",
              " 'ओठ',\n",
              " 'आत्म',\n",
              " 'आफू',\n",
              " 'आफूलाई',\n",
              " 'आफ्नै',\n",
              " 'आफ्नो',\n",
              " 'आयो',\n",
              " 'उदाहरण',\n",
              " 'उनको',\n",
              " 'उहालाई',\n",
              " 'एउटै',\n",
              " 'एक',\n",
              " 'एकदम',\n",
              " 'कतै',\n",
              " 'कम से कम',\n",
              " 'कसै',\n",
              " 'कसैले',\n",
              " 'कहाँबाट',\n",
              " 'कहिलेकाहीं',\n",
              " 'का',\n",
              " 'किन',\n",
              " 'किनभने',\n",
              " 'कुनै',\n",
              " 'कुरा',\n",
              " 'कृपया',\n",
              " 'केही',\n",
              " 'कोही',\n",
              " 'गए',\n",
              " 'गरौं',\n",
              " 'गर्छ',\n",
              " 'गर्छु',\n",
              " 'गर्नुपर्छ',\n",
              " 'गयौ',\n",
              " 'गैर',\n",
              " 'चार',\n",
              " 'चाहनुहुन्छ',\n",
              " 'चाहन्छु',\n",
              " 'चाहिए',\n",
              " 'छू',\n",
              " 'जताततै',\n",
              " 'जब',\n",
              " 'जबकि',\n",
              " 'जसको',\n",
              " 'जसबाट',\n",
              " 'जसमा',\n",
              " 'जसलाई',\n",
              " 'जसले',\n",
              " 'जस्तै',\n",
              " 'जस्तो',\n",
              " 'जस्तोसुकै',\n",
              " 'जहाँ',\n",
              " 'जान',\n",
              " 'जाहिर',\n",
              " 'जे',\n",
              " 'जो',\n",
              " 'ठीक',\n",
              " 'तत्काल',\n",
              " 'तदनुसार',\n",
              " 'तपाईको',\n",
              " 'तपाई',\n",
              " 'पर्याप्त',\n",
              " 'पहिले',\n",
              " 'पहिलो',\n",
              " 'पहिल्यै',\n",
              " 'पाँच',\n",
              " 'पाँचौं',\n",
              " 'तल',\n",
              " 'तापनी',\n",
              " 'तिनी',\n",
              " 'तिनीहरू',\n",
              " 'तिनीहरुको',\n",
              " 'तिनिहरुलाई',\n",
              " 'तिमी',\n",
              " 'तिर',\n",
              " 'तीन',\n",
              " 'तुरुन्तै',\n",
              " 'तेस्रो',\n",
              " 'तेस्कारण',\n",
              " 'पूर्व',\n",
              " 'प्रति',\n",
              " 'प्रतेक',\n",
              " 'प्लस',\n",
              " 'फेरी',\n",
              " 'बने',\n",
              " 'त्सपछि',\n",
              " 'त्सैले',\n",
              " 'त्यहाँ',\n",
              " 'थिएन',\n",
              " 'दिनुभएको',\n",
              " 'दिनुहुन्छ',\n",
              " 'दुई',\n",
              " 'देखि',\n",
              " 'बरु',\n",
              " 'बारे',\n",
              " 'बाहिर',\n",
              " 'देखिन्छ',\n",
              " 'देखियो',\n",
              " 'देखे',\n",
              " 'देखेको',\n",
              " 'देखेर',\n",
              " 'दोस्रो',\n",
              " 'धेरै',\n",
              " 'नजिकै',\n",
              " 'नत्र',\n",
              " 'नयाँ',\n",
              " 'निम्ति',\n",
              " 'बाहेक',\n",
              " 'बीच',\n",
              " 'बीचमा',\n",
              " 'भन',\n",
              " 'निम्न',\n",
              " 'निम्नानुसार',\n",
              " 'निर्दिष्ट',\n",
              " 'नौ',\n",
              " 'पक्का',\n",
              " 'पक्कै',\n",
              " 'पछि',\n",
              " 'पछिल्लो',\n",
              " 'पटक',\n",
              " 'पर्छ',\n",
              " 'पर्थ्यो',\n",
              " 'भन्छन्',\n",
              " 'भन्',\n",
              " 'भन्छु',\n",
              " 'भन्दा',\n",
              " 'भन्नुभयो',\n",
              " 'भर',\n",
              " 'भित्र',\n",
              " 'भित्री',\n",
              " 'म',\n",
              " 'मलाई',\n",
              " 'मात्र',\n",
              " 'माथि',\n",
              " 'मुख्य',\n",
              " 'मेरो',\n",
              " 'यति',\n",
              " 'यथोचित',\n",
              " 'यदि',\n",
              " 'यद्यपि',\n",
              " 'यसको',\n",
              " 'यसपछि',\n",
              " 'यसबाहेक',\n",
              " 'यसरी',\n",
              " 'यसो',\n",
              " 'यस्तो',\n",
              " 'यहाँ',\n",
              " 'यहाँसम्म',\n",
              " 'या',\n",
              " 'रही',\n",
              " 'राखे',\n",
              " 'राख्छ',\n",
              " 'राम्रो',\n",
              " 'रूप',\n",
              " 'लगभग',\n",
              " 'वरीपरी',\n",
              " 'वास्तवमा',\n",
              " 'बिरुद्ध',\n",
              " 'बिशेष',\n",
              " 'सायद',\n",
              " 'शायद',\n",
              " 'संग',\n",
              " 'संगै',\n",
              " 'सक्छ',\n",
              " 'सट्टा',\n",
              " 'सधै',\n",
              " 'सबै',\n",
              " 'सबैलाई',\n",
              " 'समय',\n",
              " 'सम्भव',\n",
              " 'सम्म',\n",
              " 'सही',\n",
              " 'साँच्चै',\n",
              " 'सात',\n",
              " 'साथ',\n",
              " 'साथै',\n",
              " 'सारा',\n",
              " 'सोही',\n",
              " 'स्पष्ट',\n",
              " 'हरे',\n",
              " 'हरेक']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  words = nltk.word_tokenize(text)\n",
        "  stopwords_removed = [word for word in words if word not in stopwords]\n",
        "  print(stopwords_removed)"
      ],
      "metadata": {
        "id": "3vhHMKk5hyM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \" Tokenization is the task of splitting text into meaning segments, called tokens\"\n",
        "preprocess(text = sent)"
      ],
      "metadata": {
        "id": "BjLU1HUxi933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b564402e-fc02-4e5c-bd86-5cb4939f79e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokenization', 'task', 'splitting', 'text', 'meaning', 'segments', ',', 'called', 'tokens']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRtyycyTjyUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming : convert words into root word or base word stem or base word - word may not have any meaning - very fast"
      ],
      "metadata": {
        "id": "HZjAWzzgka6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "BNU-vPTxksYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['change', 'changes', 'changing']\n",
        "[stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7tMCD3Xk7PJ",
        "outputId": "eb88ded0-e407-4c68-83b4-fbe6b52adf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chang', 'chang', 'chang']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['change', 'changes', 'changing', 'changer']\n",
        "[stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trZJjncElPRJ",
        "outputId": "4fbf5fcb-3b41-43ac-d2e1-f2718f92e998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chang', 'chang', 'chang', 'changer']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RS5wF9r7lcAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization : Lemmatization deals with reducing the words to its canonical dictionary from(lemma)"
      ],
      "metadata": {
        "id": "Q7GUVGsylkt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFp1b1Ivl3Bv",
        "outputId": "3cdc57fa-6845-4589-cf80-d956db4113ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words = ['change', 'changes', 'changing']\n",
        "[lemmatizer.lemmatize(word) for word in words] # dictionary meaning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYiyCaiAmIeW",
        "outputId": "907926d8-8613-4ea5-a76b-b5cb433d7ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['change', 'change', 'changing']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zq_UUDvTmnMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}